{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook take UVES images numpy arrays and compute the resnet50 descriptors\n",
    "# After that it save the descriptors in the descriptor blob in azure\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_blob_keys as cfg\n",
    "# Create the BlockBlockService that is used to call the Blob service \n",
    "# for the storage account\n",
    "account_name = cfg.AccountName\n",
    "account_key = cfg.AccountKey\n",
    "block_blob_service = BlockBlobService(account_name=account_name, account_key=account_key)\n",
    "\n",
    "cont_name_proc = cfg.ContNameProc\n",
    "block_blob_service.set_container_acl(cont_name_proc, public_access=PublicAccess.Container)\n",
    "\n",
    "cont_name_desc = cfg.ContNameDesc\n",
    "block_blob_service.set_container_acl(cont_name_desc, public_access=PublicAccess.Container)\n",
    "\n",
    "# Number of workers\n",
    "NumberWorkers=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list \"filelist\" with the blob content\n",
    "# inside the \"Azure:container/folder\" location \n",
    "def BlobList(container, folder, filelist, verbose=False):\n",
    "    \n",
    "    gen = block_blob_service.list_blobs(container, prefix=folder)\n",
    "    \n",
    "    for blob in gen:\n",
    "        file = str(blob.name).replace(folder,'')\n",
    "        filelist.append(file)\n",
    "        if verbose == True:\n",
    "            print(\"\\t Blob name: \" + blob.name)\n",
    "        \n",
    "    return filelist\n",
    "\n",
    "# Download a file \"blobfile\" from \"container\" and save it \n",
    "# in the file \"locfile\"\n",
    "def DownBlob(container, blobfile, locfile, verbose=False):\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('Downloading ' + blobfile + ' to ' + locfile)\n",
    "    \n",
    "    block_blob_service.get_blob_to_path(container, blobfile, locfile)\n",
    "\n",
    "# Uncompress data \n",
    "def UnCompress(file, verbose=False):\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('Uncompressing ' + file)\n",
    "    \n",
    "    subprocess.call(['uncompress', file])\n",
    "    #os.popen('uncompress ' + file)\n",
    "\n",
    "# Upload file \"locfile\" to the blob \"blobfile\" in container\n",
    "def UpBlob(container, blobfile, locfile, verbose=False):\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('Uploading ' + locfile + ' to ' + blobfile)\n",
    "        \n",
    "    block_blob_service.create_blob_from_path(container, blobfile, locfile, validate_content=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from scipy import sparse\n",
    "from astropy.io import fits\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.applications import nasnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4894573689325692079, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 3244626742657036009\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto( device_count = {'CPU': 4} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = keras.applications.resnet50.ResNet50(include_top=True, \n",
    "                                                 weights='imagenet', \n",
    "                                                 classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the .fits image, imname, and get the data for the corresponding extension, ext\n",
    "def get_image(imname, verbose=False):\n",
    "    \n",
    "    data = np.load(imname)\n",
    "    image = np.empty((3,data.shape[0],data.shape[1]))\n",
    "    image[0] = np.copy(data)\n",
    "    image[1] = np.copy(data)\n",
    "    image[2] = np.copy(data)\n",
    "    image = np.swapaxes(image,0,1)\n",
    "    image = np.swapaxes(image,1,2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptors from data for the model\n",
    "def get_descriptor(model, out_layer, model_input):\n",
    "    get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                      [model.get_layer(out_layer).output])\n",
    "    layer_output = get_3rd_layer_output([model_input])[0]\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of files, call to get descriptors to create the descriptors arrays \n",
    "def process_imgs(path_loc, dir_list, layer, npy_blob_name, ext):\n",
    "    \n",
    "    descriptor_len = model.get_layer(layer).output.shape[-1].value\n",
    "    descriptors = np.zeros((len(dir_list), descriptor_len))\n",
    "    \n",
    "    extension = 'ext'+str(ext)\n",
    "\n",
    "    npy_blob_name = os.path.join('numpy',npy_blob_name)\n",
    "    npy_blob_name = os.path.join(npy_blob_name,extension)\n",
    "        \n",
    "    with tqdm_notebook(total=len(dir_list)) as pbar:\n",
    "        for img_idx in range(0, len(dir_list)):\n",
    "            imgname = dir_list[img_idx]\n",
    "\n",
    "            npy_blob_name = npy_blob_name + imgname\n",
    "            path_to_file_loc = path_loc + imgname\n",
    "            loc_desc_file = path_to_file_loc.replace('.npy','_desc.npy')\n",
    "            desc_blob_name = npy_blob_name.replace('.npy','_desc.npy')\n",
    "            loc_imgname = path_to_file_loc\n",
    "            \n",
    "            DownBlob(cont_name_proc, npy_blob_name, path_to_file_loc, False)\n",
    "\n",
    "            try:\n",
    "                img = get_image(loc_imgname)\n",
    "                img = np.expand_dims(img, axis=0)\n",
    "                desc = get_descriptor(model, layer, img)\n",
    "                np.save(loc_desc_file, desc)\n",
    "                \n",
    "                while not os.path.exists(loc_desc_file):\n",
    "                    time.sleep(0.1)\n",
    "                                \n",
    "                UpBlob(cont_name_desc, desc_blob_name, loc_desc_file, False)\n",
    "            except:\n",
    "                descriptors[img_idx, :] = np.nan\n",
    "            \n",
    "            os.remove(path_to_file_loc)\n",
    "            os.remove(loc_desc_file)\n",
    "            \n",
    "            npy_blob_name = npy_blob_name.replace(imgname,'')\n",
    "            path_to_file_loc = path_to_file_loc.replace(imgname,'')\n",
    "            pbar.update(1)\n",
    "            \n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PROJECT_DIR = \"/data/notebooks/uves_jprieto/Tutorial\"\n",
    "# Model checkpoints\n",
    "CHECKPOINT_DIR = os.path.join(PROJECT_DIR, \"checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on UVES_RED_BIAS extension ext1...\n",
      "16474  of 16474  already uploaded in numpy/UVES_RED_BIAS/ext1\n",
      "Folder numpy/UVES_RED_BIAS/ext1 is ready.\n",
      "Working on UVES_RED_BIAS extension ext2...\n",
      "16474  of 16474  already uploaded in numpy/UVES_RED_BIAS/ext2\n",
      "Folder numpy/UVES_RED_BIAS/ext2 is ready.\n"
     ]
    }
   ],
   "source": [
    "# List of numpy arrays to process\n",
    "# * bias_red:\n",
    "#   - UVES_RED_BIAS (ext: 1,2)\n",
    "# * bias_blue:\n",
    "#   - UVES_BLUE_BIAS (ext: 0)\n",
    "# * blue_arc_flat:\n",
    "#   - UVES_BLUE_WAVE (ext: 1,2)\n",
    "#   - UVES_DIC1B_FLAT (ext: 0)\n",
    "#   - UVES_DIC1B_DFLAT (ext: 0)\n",
    "# * red_arc_flat:\n",
    "#   - UVES_RED_WAVE (ext: 1,2)\n",
    "#   - UVES_DIC1R_FLAT (ext: 1,2)\n",
    "# The following lines produce the resnet50 descriptors for the images inside\n",
    "# fits_folder and the corresponding extentsion \n",
    "\n",
    "check_from_list = True\n",
    "\n",
    "# Define the subdirs to be created in /descriptor based on the image type and ext\n",
    "#npyBlobSubDirs = ['UVES_BLUE_BIAS','UVES_RED_BIAS','UVES_BLUE_WAVE','UVES_DIC1B_FLAT','UVES_DIC1B_DFLAT','UVES_RED_WAVE','UVES_DIC1R_FLAT']\n",
    "# Test\n",
    "npyBlobSubDirs = ['UVES_RED_BIAS']\n",
    "\n",
    "path_loc = '../Temp'\n",
    "\n",
    "# Loof for images type folder\n",
    "for npy_blob_sub_dir in npyBlobSubDirs:\n",
    "    # Images extensions\n",
    "    \n",
    "    if npy_blob_sub_dir == 'UVES_BLUE_BIAS' or npy_blob_sub_dir == 'UVES_DIC1B_FLAT' or npy_blob_sub_dir == 'UVES_DIC1B_DFLAT':\n",
    "        Exten = [0]\n",
    "    elif npy_blob_sub_dir == 'UVES_RED_BIAS' or npy_blob_sub_dir == 'UVES_BLUE_WAVE' or npy_blob_sub_dir == 'UVES_RED_WAVE' or npy_blob_sub_dir == 'UVES_DIC1R_FLAT':\n",
    "        Exten = [1,2]\n",
    "    \n",
    "    # Loop for images extensions\n",
    "    for ext in Exten:\n",
    "        npy_files_list = []\n",
    "        extension = 'ext'+str(ext)\n",
    "        print('Working on ' + npy_blob_sub_dir + ' extension ' + extension + '...')\n",
    "        # List the images-extension data\n",
    "        npy_folder_rem = os.path.join('numpy',npy_blob_sub_dir)\n",
    "        npy_folder_rem = os.path.join(npy_folder_rem,extension)\n",
    "        \n",
    "        BlobList(cont_name_proc, npy_folder_rem, npy_files_list)\n",
    "        \n",
    "        IMG_DIRECTORY_LIST = npy_files_list\n",
    "        \n",
    "        if check_from_list:\n",
    "            check_files_list = []\n",
    "            desc_folder_rem = npy_folder_rem\n",
    "            BlobList(cont_name_desc, desc_folder_rem, check_files_list)\n",
    "            check_files_list = [file.replace('_desc','') for file in check_files_list]\n",
    "            if len(check_files_list)<len(npy_files_list):\n",
    "                check_files_list.pop(-1)\n",
    "                print(len(check_files_list),' of',len(npy_files_list),' already uploaded in ' + desc_folder_rem)\n",
    "                print('Continue...')\n",
    "            elif len(check_files_list)==len(npy_files_list):\n",
    "                print(len(check_files_list),' of',len(npy_files_list),' already uploaded in ' + desc_folder_rem)\n",
    "                print('Folder '+ desc_folder_rem + ' is ready.')\n",
    "            npy_files_list = [file for file in npy_files_list if file not in check_files_list]\n",
    "            IMG_DIRECTORY_LIST = npy_files_list\n",
    "        \n",
    "        if len(IMG_DIRECTORY_LIST)>0:\n",
    "            descs_resNet50 = process_imgs(path_loc, IMG_DIRECTORY_LIST, 'avg_pool', npy_blob_sub_dir, ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PoC ESO",
   "language": "python",
   "name": "eso"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
